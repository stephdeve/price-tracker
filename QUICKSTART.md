# üöÄ Quick Start Guide - Price Tracker B√©nin

## Option 1: D√©marrage rapide avec Docker (Recommand√©)

### 1. V√©rifier les pr√©requis
```powershell
# V√©rifier Docker
docker --version
docker-compose --version

# Si Docker n'est pas install√©, t√©l√©chargez Docker Desktop pour Windows
# https://www.docker.com/products/docker-desktop
```

### 2. Configurer l'environnement
```powershell
cd d:\dev\price-tracker-IA

# Le fichier .env a d√©j√† √©t√© cr√©√©, vous pouvez le modifier:
notepad .env

# Valeurs minimales requises pour commencer:
# - Les valeurs MySQL sont d√©j√† configur√©es
# - JWT_SECRET_KEY: changez-le pour plus de s√©curit√©
# - Le reste peut attendre pour les tests initiaux
```

### 3. D√©marrer les services
```powershell
# Construire et d√©marrer tous les containers
docker-compose up -d --build

# Attendre 30 secondes que MySQL d√©marre compl√®tement
Start-Sleep -Seconds 30

# V√©rifier que les services tournent
docker-compose ps
```

Vous devriez voir :
- ‚úÖ `price_tracker_mysql` - Running
- ‚úÖ `price_tracker_redis` - Running  
- ‚úÖ `price_tracker_backend` - Running
- ‚úÖ `price_tracker_celery_worker` - Running
- ‚úÖ `price_tracker_celery_beat` - Running

### 4. Cr√©er la base de donn√©es
```powershell
# Entrer dans le container backend
docker-compose exec backend bash

# √Ä l'int√©rieur du container:
# G√©n√©rer la migration initiale
alembic revision --autogenerate -m "Initial migration"

# Appliquer les migrations
alembic upgrade head

# Sortir du container
exit
```

### 5. Tester l'API
```powershell
# Ouvrir votre navigateur √†:
# http://localhost:8000
# http://localhost:8000/docs (Swagger UI)
```

---

## Option 2: D√©veloppement local (sans Docker)

### 1. Installer MySQL
```powershell
# T√©l√©charger MySQL 8.0 pour Windows
# https://dev.mysql.com/downloads/mysql/

# Cr√©er la base de donn√©es
mysql -u root -p
CREATE DATABASE price_tracker;
CREATE USER 'price_user'@'localhost' IDENTIFIED BY 'price_password';
GRANT ALL PRIVILEGES ON price_tracker.* TO 'price_user'@'localhost';
FLUSH PRIVILEGES;
EXIT;
```

### 2. Installer Redis
```powershell
# Option 1: Via WSL2 (recommand√©)
wsl --install
wsl
sudo apt update
sudo apt install redis-server
sudo service redis-server start

# Option 2: Redis for Windows (moins stable)
# https://github.com/microsoftarchive/redis/releases
```

### 3. Configuration Python
```powershell
cd d:\dev\price-tracker-IA\backend

# Cr√©er un environnement virtuel
python -m venv venv

# Activer l'environnement
.\venv\Scripts\Activate.ps1

# Installer les d√©pendances
pip install -r requirements.txt

# Installer Playwright browsers
playwright install chromium
```

### 4. Configurer .env (local)
```powershell
# Modifier .env pour connexion locale
notepad .env
```

Changez ces lignes:
```env
DATABASE_URL=mysql+aiomysql://price_user:price_password@localhost:3306/price_tracker
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/1
```

### 5. Lancer l'application
```powershell
# Terminal 1: Backend FastAPI
cd backend
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Terminal 2: Celery Worker
cd backend
celery -A app.tasks.celery_app worker --loglevel=info --pool=solo

# Terminal 3: Celery Beat
cd backend
celery -A app.tasks.celery_app beat --loglevel=info
```

---

## üß™ Tester le Scraping (Jumia B√©nin)

### M√©thode 1: Via Python directement
```powershell
# Entrer dans le container (si Docker)
docker-compose exec backend python

# Ou activer venv (si local)
# .\backend\venv\Scripts\Activate.ps1
# cd backend
# python
```

```python
import asyncio
from app.services.scraper.jumia_scraper import JumiaScraper

async def test_scraping():
    # Remplacez par une vraie URL de produit Jumia B√©nin
    url = "https://www.jumia.com.bj/..."  # Ex: Un t√©l√©phone populaire
    
    async with JumiaScraper() as scraper:
        print("üîç Scraping en cours...")
        data = await scraper.scrape_product(url)
        
        if data:
            print(f"‚úÖ Produit: {data['name']}")
            print(f"üí∞ Prix: {data['price']} {data['currency']}")
            print(f"üì∏ Image: {data['image_url'][:50]}...")
        else:
            print("‚ùå √âchec du scraping")

# Lancer le test
asyncio.run(test_scraping())
```

### M√©thode 2: Via un script de test
Cr√©ez `backend/test_scraper.py`:
```python
import asyncio
from app.services.scraper.jumia_scraper import JumiaScraper

async def main():
    # Liste de produits Jumia B√©nin √† tester
    test_urls = [
        "https://www.jumia.com.bj/...",  # Ajoutez des URLs r√©elles
    ]
    
    async with JumiaScraper() as scraper:
        for url in test_urls:
            print(f"\n{'='*60}")
            print(f"Testing: {url}")
            print('='*60)
            
            data = await scraper.scrape_product(url)
            
            if data:
                for key, value in data.items():
                    print(f"{key}: {value}")
            else:
                print("FAILED")

if __name__ == "__main__":
    asyncio.run(main())
```

Puis lancez:
```powershell
docker-compose exec backend python test_scraper.py
# Ou si local: python backend/test_scraper.py
```

---

## üì± Installer Ollama (IA Gratuite)

### Windows
```powershell
# 1. T√©l√©charger Ollama depuis https://ollama.ai
# 2. Installer l'application
# 3. Ouvrir PowerShell et lancer:

ollama pull llama3.2

# V√©rifier que √ßa fonctionne
ollama run llama3.2 "Bonjour, parle-moi du B√©nin"

# Ollama sera accessible sur http://localhost:11434
```

### Linux / WSL
```bash
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull llama3.2
```

---

## üîß Commandes Utiles

### Docker
```powershell
# Voir les logs
docker-compose logs -f backend
docker-compose logs -f celery_worker

# Red√©marrer un service
docker-compose restart backend

# Arr√™ter tout
docker-compose down

# Nettoyer et reconstruire
docker-compose down -v
docker-compose up -d --build
```

### Base de donn√©es
```powershell
# Acc√©der √† MySQL
docker-compose exec mysql mysql -u price_user -pprice_password price_tracker

# Voir les tables
SHOW TABLES;

# Voir les utilisateurs
SELECT * FROM users;
```

### Alembic (Migrations)
```powershell
# Cr√©er une nouvelle migration
docker-compose exec backend alembic revision --autogenerate -m "Description"

# Appliquer les migrations
docker-compose exec backend alembic upgrade head

# Revenir en arri√®re
docker-compose exec backend alembic downgrade -1

# Voir l'historique
docker-compose exec backend alembic history
```

---

## ‚úÖ V√©rification de l'installation

### Checklist
- [ ] Docker Desktop install√© et en cours d'ex√©cution
- [ ] `docker-compose ps` montre tous les services "Up"
- [ ] http://localhost:8000 affiche le message de bienvenue
- [ ] http://localhost:8000/docs affiche Swagger UI
- [ ] Alembic migrations appliqu√©es (tables cr√©√©es dans MySQL)
- [ ] Ollama install√© et mod√®le llama3.2 t√©l√©charg√©
- [ ] Test de scraping Jumia r√©ussi

### Probl√®mes courants

**Port 3306 d√©j√† utilis√© (MySQL)**
```powershell
# Trouver le processus
netstat -ano | findstr :3306
# Arr√™ter le service MySQL existant ou changer le port dans docker-compose.yml
```

**Port 6379 d√©j√† utilis√© (Redis)**
```powershell
# M√™me proc√©dure
netstat -ano | findstr :6379
```

**Playwright ne fonctionne pas**
```powershell
# R√©installer les browsers
docker-compose exec backend playwright install chromium
docker-compose exec backend playwright install-deps chromium
```

---

## üéØ Prochaines √©tapes

1. ‚úÖ Infrastructure ready
2. ‚úÖ Database models cr√©√©s
3. ‚úÖ Scraping Jumia fonctionnel
4. **SUIVANT**: Cr√©er les endpoints API (auth, products)
5. **PUIS**: Frontend React
6. **ENFIN**: Int√©gration KKiapay  

---

Need help? Les logs sont votre ami! üìã
```powershell
docker-compose logs -f
```
